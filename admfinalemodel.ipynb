{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOikleTmtBoFwimDGnwVO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbvss199/colab_notebooks/blob/main/admfinalemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wOCSnE1PfVw"
      },
      "outputs": [],
      "source": [
        "#importing all the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,TensorDataset, random_split, WeightedRandomSampler\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "0CqZF0r9PiqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('pre-processed-data_college_code.xlsx')"
      ],
      "metadata": {
        "id": "ycOcYWz2Pktp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zppr72fm6uo",
        "outputId": "07aab3cf-f89d-4eb7-ea3c-8cc6829e66fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Application Major', 'Scholarship_Awarded', 'Application CGPA',\n",
              "       'FAFSA Filed', 'High School Code', 'Financial Aid Appeal',\n",
              "       'Accepted Student Day Event Attended', 'Campus Visits - Person',\n",
              "       'Campus Visits - App', 'Logins Before Admit', 'Acceptance Call Success',\n",
              "       'Application Consider Test Scores', 'Application ACRK',\n",
              "       'Waitlist Confirmed Date', 'Emails Sent', 'Emails Opened',\n",
              "       'Was Inquiry', 'Athlete', 'admitted', 'Address 1 Region_Midwest',\n",
              "       'Address 1 Region_Military', 'Address 1 Region_Northeast',\n",
              "       'Address 1 Region_South', 'Address 1 Region_Southwest',\n",
              "       'Address 1 Region_Territory', 'Address 1 Region_West',\n",
              "       'Application Housing_Commuter', 'Application Housing_Residential',\n",
              "       'Application Enroll Status_Full Time',\n",
              "       'Application Enroll Status_Part Time', 'Person Sex_F', 'Person Sex_M',\n",
              "       'Person Sex_Unknown', 'High School Region_Midwest',\n",
              "       'High School Region_Military', 'High School Region_Northeast',\n",
              "       'High School Region_South', 'High School Region_Southwest',\n",
              "       'High School Region_Territory', 'High School Region_West',\n",
              "       'Application Span', 'Admission Span', 'Application College_00',\n",
              "       'Application College_CAS', 'Application College_COB',\n",
              "       'Application College_HCLC', 'Application College_ID',\n",
              "       'Application College_SHS', 'Application College_TCOE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs=data.drop(['admitted'],axis=1).to_numpy()\n",
        "labels=data['admitted'].to_numpy()"
      ],
      "metadata": {
        "id": "G8bFCTy2Pn65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embedding_dimension=len(set(inputs[:,0]))\n",
        "input_embedding_dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RofJUaufPp4z",
        "outputId": "a7e16211-8523-48e9-9280-23c36dfea89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(inputs[:,4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXGdF4ulozsl",
        "outputId": "2e07a756-ba3e-44f7-f11c-0088bf785646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3032"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    inputs, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "# Convert to PyTorch tensors only once\n",
        "train_inputs = torch.from_numpy(train_inputs).float()\n",
        "test_inputs = torch.from_numpy(test_inputs).float()\n",
        "train_labels = torch.from_numpy(train_labels).int()\n",
        "test_labels = torch.from_numpy(test_labels).int()"
      ],
      "metadata": {
        "id": "_-B7_zS1Pqdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The TensorDataset class in PyTorch is a utility class that is used to wrap data tensors (such as features and labels)\n",
        "#This class is particularly useful when you want to work with datasets where features and labels are already stored as tensors.\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "wErq6YmtQymd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# class NeuralNetwork(nn.Module):\n",
        "#     def __init__(self, i, h_size, h_next_size, h_next_next_size=19, n_classes=2,\n",
        "#                  how_many_layers=4, embedding_dim=12):\n",
        "#         super(NeuralNetwork, self).__init__()\n",
        "\n",
        "#         features = i.shape[1]  # Total number of input features\n",
        "\n",
        "#         self.major_embedding = nn.Embedding(input_embedding_dimension, embedding_dim)\n",
        "#         # Input to fc1 will be (features - 1) continuous + embedding_dim\n",
        "#         self.fc1 = nn.Linear(features - 1 + embedding_dim, h_size)\n",
        "#         self.layers = how_many_layers\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             self.fc2 = nn.Linear(h_size, n_classes)\n",
        "#         elif self.layers == 3:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, n_classes)\n",
        "#         elif self.layers == 4:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, h_next_next_size)\n",
        "#             self.fc5 = nn.Linear(h_next_next_size, n_classes)\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         # Ensure input is float and extract categorical/continuous features\n",
        "#         categorical_input = X[:, 0].long()  # First column: categorical (encoded)\n",
        "#         continuous_input = X[:, 1:].float() # Rest: continuous features\n",
        "\n",
        "#         # Apply embedding\n",
        "#         embedded = self.major_embedding(categorical_input)  # Shape: [batch_size, embedding_dim]\n",
        "#         # Concatenate with continuous features\n",
        "#         X = torch.cat((embedded, continuous_input), dim=1)  # Shape: [batch_size, embedding_dim + (features-1)]\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = self.fc2(X)\n",
        "#         elif self.layers == 3:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = F.relu(self.fc3(X))\n",
        "#             X = self.fc4(X)\n",
        "#         elif self.layers == 4:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = torch.tanh(self.fc3(X))\n",
        "#             X = F.sigmoid(self.fc4(X))\n",
        "#             X = self.fc5(X)\n",
        "\n",
        "#         return X\n",
        "\n",
        "\n",
        "# net = NeuralNetwork(train_inputs, h_size=27, h_next_size=22, how_many_layers=4)\n",
        "# print(f\"Expected input features to fc1: {train_inputs.shape[1] - 1 + 8}\")  # Debug print\n",
        "# print(f\"fc1 weight shape: {net.fc1.weight.shape}\")  # Debug printn_epochs = 600\n",
        "\n",
        "\n",
        "# n_epochs = 600\n",
        "# learning_rate = 0.001\n",
        "# decay_rate = learning_rate / n_epochs\n",
        "# optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "# lambda_reg = 0.01\n",
        "# lambda_entropy = 0\n",
        "\n",
        "\n",
        "# def loss_fn(model, outputs, targets):\n",
        "#     # Convert labels to numpy\n",
        "#     y_train = train_labels.numpy()\n",
        "\n",
        "#     # Compute class weights\n",
        "#     class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "#     # Convert to PyTorch tensor\n",
        "#     class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "#     cross_entropy = nn.functional.cross_entropy(outputs, targets,weight=class_weights_tensor)\n",
        "#     l2_regularization = 0\n",
        "#     entropy_regularization = 0\n",
        "\n",
        "#     for param in model.parameters():\n",
        "#         l2_regularization += torch.norm(param, p=2) ** 2\n",
        "#         entropy_regularization += torch.mean(torch.sum(-outputs * torch.log(outputs), dim=1))\n",
        "\n",
        "#     loss = cross_entropy + lambda_reg * l2_regularization\n",
        "#     return loss\n",
        "\n",
        "# def test_instance(model):\n",
        "#     y_t = []\n",
        "#     y_s = []\n",
        "#     loss = 0\n",
        "#     acc = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in test_loader:\n",
        "#             outputs = model(inputs)\n",
        "#             loss += loss_fn(model, outputs, labels.long())\n",
        "#             y_t.extend(labels.numpy().astype('int'))\n",
        "#             y_s.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "#     acc = accuracy_score(y_t, y_s)\n",
        "#     return loss, acc\n",
        "\n",
        "# iteration = 0\n",
        "# counter = 0\n",
        "\n",
        "# for epoch in range(n_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     total = 0  # No. of total predictions\n",
        "#     correct = 0  # No. of correct predictions\n",
        "\n",
        "#     for i, (inputs, labels) in enumerate(train_loader):\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = net(inputs)\n",
        "#         loss = loss_fn(net, outputs, labels.long())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item() * inputs.size(0)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "#     epoch_loss = running_loss / len(train_loader.dataset)  # Loss in every epoch\n",
        "#     epoch_acc = correct / total  # Accuracy for every epoch\n",
        "\n",
        "#     if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "#         print(f'Epoch: {epoch + 1}/{n_epochs} | pLoss: {running_loss / len(inputs)} | Accuracy: {epoch_acc} | Loss: {epoch_loss}')\n",
        "\n",
        "#     if epoch % 50 == 0:\n",
        "#         test_loss, test_acc = test_instance(net)\n",
        "#         print(f'Epoch: {epoch + 1} | The test data Accuracy = {test_acc} | Test Loss = {test_loss}')\n",
        "\n",
        "#         if counter < test_acc:\n",
        "#             save_net = net\n",
        "#             counter = test_acc\n",
        "\n",
        "# y_true = []\n",
        "# y_scores = []\n",
        "# test_loss = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in test_loader:\n",
        "#         outputs = save_net(inputs)\n",
        "#         test_loss += loss_fn(net, outputs, labels.long())\n",
        "#         y_true.extend(labels.numpy().astype('int'))\n",
        "#         y_scores.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "\n",
        "# accuracy = accuracy_score(y_true, y_scores)\n",
        "# precision = precision_score(y_true, y_scores)\n",
        "# recall = recall_score(y_true, y_scores)\n",
        "# f1_val = f1_score(y_true, y_scores)\n",
        "# auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "# print('Accuracy: {:.4f}'.format(accuracy))\n",
        "# print('Precision: {:.4f}'.format(precision))\n",
        "# print('Recall: {:.4f}'.format(recall))\n",
        "# print('F1 Score: {:.4f}'.format(f1_val))\n",
        "# print('AUROC Score: {:.4f}'.format(auc_roc))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EgF-CN61PvYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# net"
      ],
      "metadata": {
        "id": "KApLkUkEg08J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# embedding_matrix = net.major_embedding.weight\n",
        "# cos_sim = F.cosine_similarity(embedding_matrix.unsqueeze(1), embedding_matrix.unsqueeze(0), dim=2)\n",
        "\n",
        "# # Set diagonal elements to -1 to ignore self-similarity (1.0 for identical vectors)\n",
        "# cos_sim.fill_diagonal_(-1)\n",
        "\n",
        "# # Define a similarity threshold (e.g., 0.8 for high similarity)\n",
        "# threshold = 0.8\n",
        "\n",
        "# # Find pairs of indices where similarity is high\n",
        "# similar_indices = torch.nonzero(cos_sim > threshold, as_tuple=False)\n",
        "\n",
        "# # Print the highly similar tensor indices\n",
        "# print(\"Highly similar vector indices (pairs):\\n\", similar_indices)\n"
      ],
      "metadata": {
        "id": "AgVz1PSdglTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# # Print the matrix\n",
        "# print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# # Plot the Confusion Matrix\n",
        "# plt.figure(figsize=(6, 5))\n",
        "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "# plt.xlabel(\"Predicted Label\")\n",
        "# plt.ylabel(\"True Label\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.show()\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# # Extract TP, TN, FP, FN\n",
        "# TN = cm[0, 0]  # True Negative\n",
        "# FP = cm[0, 1]  # False Positive\n",
        "# FN = cm[1, 0]  # False Negative\n",
        "# TP = cm[1, 1]  # True Positive\n",
        "\n",
        "# print(f\"True Positives (TP): {TP}\")\n",
        "# print(f\"False Positives (FP): {FP}\")\n",
        "# print(f\"True Negatives (TN): {TN}\")\n",
        "# print(f\"False Negatives (FN): {FN}\")\n"
      ],
      "metadata": {
        "id": "NF64JJpAQzvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High school embedding\n"
      ],
      "metadata": {
        "id": "Eltn9jpEmrK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(inputs[:,4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6xV1aLFm2LC",
        "outputId": "cbacfc04-165a-4dcd-bfa6-9090b33f414b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3032"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, i, h_size, h_next_size, h_next_next_size=19, n_classes=2,\n",
        "                 how_many_layers=4, embedding_dim=12,hs_embedding_dim=50):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        features = i.shape[1]  # Total number of input features\n",
        "\n",
        "        self.major_embedding = nn.Embedding(input_embedding_dimension, embedding_dim)\n",
        "\n",
        "        #embedding layer for the high school codes\n",
        "        self.hs_embedding=nn.Embedding(len(set(inputs[:,4])),hs_embedding_dim)\n",
        "\n",
        "        # Input to fc1 will be (features - 2) continuous + embedding_dim\n",
        "        self.fc1 = nn.Linear(features - 2 + embedding_dim + hs_embedding_dim, h_size)\n",
        "        self.layers = how_many_layers\n",
        "\n",
        "        if self.layers == 2:\n",
        "            self.fc2 = nn.Linear(h_size, n_classes)\n",
        "        elif self.layers == 3:\n",
        "            self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "            self.fc4 = nn.Linear(h_next_size, n_classes)\n",
        "        elif self.layers == 4:\n",
        "            self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "            self.fc4 = nn.Linear(h_next_size, h_next_next_size)\n",
        "            self.fc5 = nn.Linear(h_next_next_size, n_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Ensure input is float and extract categorical/continuous features\n",
        "        categorical_input = X[:, 0].long()  # First column: categorical (encoded)\n",
        "        hs_input = X[:, 4].long()\n",
        "\n",
        "        #continuous_input = X[:, 1:].float() # Rest: continuous features\n",
        "        continuous_indices = [i for i in range(X.shape[1]) if i not in [0, 4]]\n",
        "        continuous_input = X[:, continuous_indices].float()\n",
        "\n",
        "        # Apply embedding\n",
        "        embedded = self.major_embedding(categorical_input)  # Shape: [batch_size, embedding_dim]\n",
        "        hs_embedded = self.hs_embedding(hs_input)\n",
        "\n",
        "        # Concatenate with continuous features\n",
        "        X = torch.cat((embedded,hs_embedded, continuous_input), dim=1)  # Shape: [batch_size, embedding_dim + (features-1)]\n",
        "\n",
        "        if self.layers == 2:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = self.fc2(X)\n",
        "        elif self.layers == 3:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = F.relu(self.fc3(X))\n",
        "            X = self.fc4(X)\n",
        "        elif self.layers == 4:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = torch.tanh(self.fc3(X))\n",
        "            X = F.sigmoid(self.fc4(X))\n",
        "            X = self.fc5(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "net = NeuralNetwork(train_inputs, h_size=27, h_next_size=22, how_many_layers=4)\n",
        "print(f\"Expected input features to fc1: {train_inputs.shape[1] - 1 + 8}\")  # Debug print\n",
        "print(f\"fc1 weight shape: {net.fc1.weight.shape}\")  # Debug printn_epochs = 600\n",
        "\n",
        "\n",
        "n_epochs = 600\n",
        "learning_rate = 0.001\n",
        "decay_rate = learning_rate / n_epochs\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "lambda_reg = 0.01\n",
        "lambda_entropy = 0\n",
        "\n",
        "\n",
        "def loss_fn(model, outputs, targets):\n",
        "    # Convert labels to numpy\n",
        "    y_train = train_labels.numpy()\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "    cross_entropy = nn.functional.cross_entropy(outputs, targets,weight=class_weights_tensor)\n",
        "    l2_regularization = 0\n",
        "    entropy_regularization = 0\n",
        "\n",
        "    for param in model.parameters():\n",
        "        l2_regularization += torch.norm(param, p=2) ** 2\n",
        "        entropy_regularization += torch.mean(torch.sum(-outputs * torch.log(outputs), dim=1))\n",
        "\n",
        "    loss = cross_entropy + lambda_reg * l2_regularization\n",
        "    return loss\n",
        "\n",
        "def test_instance(model):\n",
        "    y_t = []\n",
        "    y_s = []\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss += loss_fn(model, outputs, labels.long())\n",
        "            y_t.extend(labels.numpy().astype('int'))\n",
        "            y_s.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "    acc = accuracy_score(y_t, y_s)\n",
        "    return loss, acc\n",
        "\n",
        "iteration = 0\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    total = 0  # No. of total predictions\n",
        "    correct = 0  # No. of correct predictions\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(net, outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)  # Loss in every epoch\n",
        "    epoch_acc = correct / total  # Accuracy for every epoch\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "        print(f'Epoch: {epoch + 1}/{n_epochs} | pLoss: {running_loss / len(inputs)} | Accuracy: {epoch_acc} | Loss: {epoch_loss}')\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        test_loss, test_acc = test_instance(net)\n",
        "        print(f'Epoch: {epoch + 1} | The test data Accuracy = {test_acc} | Test Loss = {test_loss}')\n",
        "\n",
        "        if counter < test_acc:\n",
        "            save_net = net\n",
        "            counter = test_acc\n",
        "\n",
        "y_true = []\n",
        "y_scores = []\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = save_net(inputs)\n",
        "        test_loss += loss_fn(net, outputs, labels.long())\n",
        "        y_true.extend(labels.numpy().astype('int'))\n",
        "        y_scores.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_scores)\n",
        "precision = precision_score(y_true, y_scores)\n",
        "recall = recall_score(y_true, y_scores)\n",
        "f1_val = f1_score(y_true, y_scores)\n",
        "auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn3IyqhEYQ2c",
        "outputId": "1d179e10-ed89-4b2b-ad17-a676f2df5419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected input features to fc1: 55\n",
            "fc1 weight shape: torch.Size([27, 108])\n",
            "Epoch: 1/600 | pLoss: 725512.7387424045 | Accuracy: 0.9191100020794344 | Loss: 1357.7905279021918\n",
            "Epoch: 1 | The test data Accuracy = 0.935966735966736 | Test Loss = 45620.73046875\n",
            "Epoch: 11/600 | pLoss: 68887.3301595052 | Accuracy: 0.9498856311083386 | Loss: 128.9220152704402\n",
            "Epoch: 21/600 | pLoss: 4998.381616592407 | Accuracy: 0.950509461426492 | Loss: 9.354425982393776\n",
            "Epoch: 31/600 | pLoss: 313.13728443781537 | Accuracy: 0.950509461426492 | Loss: 0.5860335953296607\n",
            "Epoch: 41/600 | pLoss: 123.31917132602797 | Accuracy: 0.949677687668954 | Loss: 0.23079071364821205\n",
            "Epoch: 51/600 | pLoss: 119.2380240658919 | Accuracy: 0.9480141401538782 | Loss: 0.2231528834670466\n",
            "Epoch: 51 | The test data Accuracy = 0.9501039501039501 | Test Loss = 8.539522171020508\n",
            "Epoch: 61/600 | pLoss: 119.15467440419727 | Accuracy: 0.9501975462674153 | Loss: 0.22299689532912775\n",
            "Epoch: 71/600 | pLoss: 119.05294522974226 | Accuracy: 0.950093574547723 | Loss: 0.2228065100993305\n",
            "Epoch: 81/600 | pLoss: 118.39749360084534 | Accuracy: 0.9501975462674153 | Loss: 0.22157983830476358\n",
            "Epoch: 91/600 | pLoss: 118.01938889424007 | Accuracy: 0.950093574547723 | Loss: 0.2208722187665129\n",
            "Epoch: 101/600 | pLoss: 118.33282235264778 | Accuracy: 0.9520690372218756 | Loss: 0.22145880664874817\n",
            "Epoch: 101 | The test data Accuracy = 0.9509355509355509 | Test Loss = 8.098174095153809\n",
            "Epoch: 111/600 | pLoss: 117.5128064552943 | Accuracy: 0.9513412351840299 | Loss: 0.2199241543143374\n",
            "Epoch: 121/600 | pLoss: 116.77698728442192 | Accuracy: 0.9518610937824912 | Loss: 0.21854707539193122\n",
            "Epoch: 131/600 | pLoss: 116.43959128194385 | Accuracy: 0.9520690372218756 | Loss: 0.21791564182522244\n",
            "Epoch: 141/600 | pLoss: 117.89447932276461 | Accuracy: 0.9503015179871075 | Loss: 0.22063845163337106\n",
            "Epoch: 151/600 | pLoss: 117.72203108999464 | Accuracy: 0.9516531503431067 | Loss: 0.2203157163256294\n",
            "Epoch: 151 | The test data Accuracy = 0.9617463617463617 | Test Loss = 8.542353630065918\n",
            "Epoch: 161/600 | pLoss: 117.41796610090468 | Accuracy: 0.9503015179871075 | Loss: 0.21974666144897942\n",
            "Epoch: 171/600 | pLoss: 117.45257966551516 | Accuracy: 0.9514452069037221 | Loss: 0.2198114404220496\n",
            "Epoch: 181/600 | pLoss: 118.03772015372913 | Accuracy: 0.9518610937824912 | Loss: 0.22090652555283055\n",
            "Epoch: 191/600 | pLoss: 119.16152671972911 | Accuracy: 0.9489498856311084 | Loss: 0.22300971937566272\n",
            "Epoch: 201/600 | pLoss: 116.94964569144778 | Accuracy: 0.9520690372218756 | Loss: 0.21887020403889168\n",
            "Epoch: 201 | The test data Accuracy = 0.9559251559251559 | Test Loss = 8.187735557556152\n",
            "Epoch: 211/600 | pLoss: 116.89176078140736 | Accuracy: 0.9515491786234145 | Loss: 0.21876187295335126\n",
            "Epoch: 221/600 | pLoss: 117.13200038505926 | Accuracy: 0.9524849241006447 | Loss: 0.21921147919848893\n",
            "Epoch: 231/600 | pLoss: 117.04379110866122 | Accuracy: 0.9508213765855688 | Loss: 0.21904639633561054\n",
            "Epoch: 241/600 | pLoss: 117.20698912607298 | Accuracy: 0.950093574547723 | Loss: 0.2193518199489825\n",
            "Epoch: 251/600 | pLoss: 116.98072877526283 | Accuracy: 0.9522769806612601 | Loss: 0.21892837574908827\n",
            "Epoch: 251 | The test data Accuracy = 0.9609147609147609 | Test Loss = 8.277715682983398\n",
            "Epoch: 261/600 | pLoss: 117.35347394314077 | Accuracy: 0.9518610937824912 | Loss: 0.21962596495909065\n",
            "Epoch: 271/600 | pLoss: 116.356134613355 | Accuracy: 0.9519650655021834 | Loss: 0.217759453424869\n",
            "Epoch: 281/600 | pLoss: 118.13869534101751 | Accuracy: 0.9530047826991058 | Loss: 0.2210954997024657\n",
            "Epoch: 291/600 | pLoss: 117.56062537514501 | Accuracy: 0.9501975462674153 | Loss: 0.2200136469902901\n",
            "Epoch: 301/600 | pLoss: 118.27012746698327 | Accuracy: 0.9508213765855688 | Loss: 0.22134147373733612\n",
            "Epoch: 301 | The test data Accuracy = 0.9376299376299376 | Test Loss = 8.340472221374512\n",
            "Epoch: 311/600 | pLoss: 117.35998425549931 | Accuracy: 0.9523809523809523 | Loss: 0.21963814894978037\n",
            "Epoch: 321/600 | pLoss: 117.11701898442374 | Accuracy: 0.9512372634643377 | Loss: 0.21918344164271442\n",
            "Epoch: 331/600 | pLoss: 117.08355313705073 | Accuracy: 0.9520690372218756 | Loss: 0.2191208106120725\n",
            "Epoch: 341/600 | pLoss: 118.33521440790759 | Accuracy: 0.9521730089415679 | Loss: 0.2214632833585295\n",
            "Epoch: 351/600 | pLoss: 118.38095679879189 | Accuracy: 0.9514452069037221 | Loss: 0.22154888982930485\n",
            "Epoch: 351 | The test data Accuracy = 0.9426195426195426 | Test Loss = 8.093289375305176\n",
            "Epoch: 361/600 | pLoss: 116.79354935222202 | Accuracy: 0.9518610937824912 | Loss: 0.21857807115200628\n",
            "Epoch: 371/600 | pLoss: 116.80576768848631 | Accuracy: 0.950925348305261 | Loss: 0.21860093765780345\n",
            "Epoch: 381/600 | pLoss: 116.88953020506435 | Accuracy: 0.9527968392597214 | Loss: 0.2187576984499021\n",
            "Epoch: 391/600 | pLoss: 117.82209090391795 | Accuracy: 0.9517571220627989 | Loss: 0.22050297736229185\n",
            "Epoch: 401/600 | pLoss: 117.20269543594785 | Accuracy: 0.9521730089415679 | Loss: 0.21934378434675206\n",
            "Epoch: 401 | The test data Accuracy = 0.9388773388773389 | Test Loss = 8.318805694580078\n",
            "Epoch: 411/600 | pLoss: 117.63238239785035 | Accuracy: 0.9529008109794136 | Loss: 0.22014793960920215\n",
            "Epoch: 421/600 | pLoss: 118.05432738198175 | Accuracy: 0.950509461426492 | Loss: 0.220937605830284\n",
            "Epoch: 431/600 | pLoss: 117.09129422075219 | Accuracy: 0.9521730089415679 | Loss: 0.21913529798019749\n",
            "Epoch: 441/600 | pLoss: 117.51765962772899 | Accuracy: 0.9532127261384903 | Loss: 0.21993323698264938\n",
            "Epoch: 451/600 | pLoss: 118.07205940617456 | Accuracy: 0.9503015179871075 | Loss: 0.2209707911531651\n",
            "Epoch: 451 | The test data Accuracy = 0.9563409563409564 | Test Loss = 8.267687797546387\n",
            "Epoch: 461/600 | pLoss: 118.4507655998071 | Accuracy: 0.9511332917446454 | Loss: 0.22167953636894655\n",
            "Epoch: 471/600 | pLoss: 117.3054457075066 | Accuracy: 0.9513412351840299 | Loss: 0.2195360805505426\n",
            "Epoch: 481/600 | pLoss: 117.2647722048892 | Accuracy: 0.9507174048658765 | Loss: 0.2194599604583079\n",
            "Epoch: 491/600 | pLoss: 116.6209258089463 | Accuracy: 0.9515491786234145 | Loss: 0.21825500775223886\n",
            "Epoch: 501/600 | pLoss: 117.34178176356687 | Accuracy: 0.9522769806612601 | Loss: 0.21960408315078017\n",
            "Epoch: 501 | The test data Accuracy = 0.930977130977131 | Test Loss = 8.48211669921875\n",
            "Epoch: 511/600 | pLoss: 117.89905758036508 | Accuracy: 0.9510293200249532 | Loss: 0.22064701980105753\n",
            "Epoch: 521/600 | pLoss: 117.24902061786916 | Accuracy: 0.9516531503431067 | Loss: 0.21943048150568153\n",
            "Epoch: 531/600 | pLoss: 117.73837173316214 | Accuracy: 0.9507174048658765 | Loss: 0.22034629769150743\n",
            "Epoch: 541/600 | pLoss: 117.9321795768208 | Accuracy: 0.9514452069037221 | Loss: 0.2207090073178181\n",
            "Epoch: 551/600 | pLoss: 117.13761571960316 | Accuracy: 0.9520690372218756 | Loss: 0.21922198824629413\n",
            "Epoch: 551 | The test data Accuracy = 0.9546777546777547 | Test Loss = 8.472567558288574\n",
            "Epoch: 561/600 | pLoss: 117.24817248516612 | Accuracy: 0.9520690372218756 | Loss: 0.2194288942329996\n",
            "Epoch: 571/600 | pLoss: 117.8012278676033 | Accuracy: 0.9510293200249532 | Loss: 0.22046393237854642\n",
            "Epoch: 581/600 | pLoss: 117.40724307629797 | Accuracy: 0.9519650655021834 | Loss: 0.21972659340542353\n",
            "Epoch: 591/600 | pLoss: 117.57193003926012 | Accuracy: 0.9510293200249532 | Loss: 0.22003480356692476\n",
            "Epoch: 600/600 | pLoss: 116.07258957955572 | Accuracy: 0.9521730089415679 | Loss: 0.21722880145893148\n",
            "Accuracy: 0.9372\n",
            "Precision: 0.6628\n",
            "Recall: 0.9863\n",
            "F1 Score: 0.7929\n",
            "AUROC Score: 0.9584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# Print the matrix\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot the Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "TN = cm[0, 0]  # True Negative\n",
        "FP = cm[0, 1]  # False Positive\n",
        "FN = cm[1, 0]  # False Negative\n",
        "TP = cm[1, 1]  # True Positive\n",
        "\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "8l8sXrVPvBL7",
        "outputId": "618fdac0-caec-4fcf-9f72-90b256e76bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1965  147]\n",
            " [   4  289]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives (TP): 289\n",
            "False Positives (FP): 147\n",
            "True Negatives (TN): 1965\n",
            "False Negatives (FN): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "eUarW6j20WDV",
        "outputId": "21b6414b-df4f-4035-d446-66c67566ae38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c66a25f7c25c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/my_model.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net)\n",
        "print(net.state_dict().keys())  # Should print parameter names\n",
        "torch.save(net.state_dict(),'final_model.pth')\n",
        "torch.save(net, 'final_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_PvnB7vB7l",
        "outputId": "ca56e47a-c995-4956-e239-0ac0d76ce8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (major_embedding): Embedding(102, 12)\n",
            "  (hs_embedding): Embedding(3032, 50)\n",
            "  (fc1): Linear(in_features=108, out_features=27, bias=True)\n",
            "  (fc3): Linear(in_features=27, out_features=22, bias=True)\n",
            "  (fc4): Linear(in_features=22, out_features=19, bias=True)\n",
            "  (fc5): Linear(in_features=19, out_features=2, bias=True)\n",
            ")\n",
            "odict_keys(['major_embedding.weight', 'hs_embedding.weight', 'fc1.weight', 'fc1.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hp training"
      ],
      "metadata": {
        "id": "8hMbWeAz3Gqw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQ5RtlxQ3fGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pca\n"
      ],
      "metadata": {
        "id": "kDwEcUtCH0Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Importing all the necessary libraries\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F  # Fixed torch.functional to torch.nn.functional\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import sys\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "# from torch.utils.data import DataLoader, TensorDataset, random_split, WeightedRandomSampler\n",
        "# import torch.optim as optim\n",
        "# from torchsummary import summary\n",
        "\n",
        "# # Assuming 'data' is your DataFrame\n",
        "# inputs = data.drop(['admitted'], axis=1).to_numpy()\n",
        "# labels = data['admitted'].to_numpy()\n",
        "\n",
        "# # Train-test split\n",
        "# train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "#     inputs, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "# )\n",
        "\n",
        "# # Convert to NumPy for PCA preprocessing\n",
        "# train_inputs_np = train_inputs\n",
        "# test_inputs_np = test_inputs\n",
        "\n",
        "# # Identify continuous features (excluding categorical columns 0 and 4)\n",
        "# continuous_indices = [i for i in range(train_inputs_np.shape[1]) if i not in [0, 4]]\n",
        "# X_train_continuous = train_inputs_np[:, continuous_indices]\n",
        "# X_test_continuous = test_inputs_np[:, continuous_indices]\n",
        "\n",
        "# # Standardize the continuous features\n",
        "# scaler = StandardScaler()\n",
        "# X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
        "# X_test_continuous_scaled = scaler.transform(X_test_continuous)  # Use training scaler\n",
        "\n",
        "# # Apply PCA (e.g., retain 95% variance)\n",
        "# pca = PCA(n_components=0.95)  # Adjust n_components as needed\n",
        "# X_train_continuous_pca = pca.fit_transform(X_train_continuous_scaled)\n",
        "# X_test_continuous_pca = pca.transform(X_test_continuous_scaled)\n",
        "\n",
        "# print(f\"Reduced continuous features from {X_train_continuous.shape[1]} to {X_train_continuous_pca.shape[1]}\")\n",
        "\n",
        "# # Convert PCA-transformed data to PyTorch tensors\n",
        "# X_train_continuous_pca_tensor = torch.tensor(X_train_continuous_pca, dtype=torch.float32)\n",
        "# X_test_continuous_pca_tensor = torch.tensor(X_test_continuous_pca, dtype=torch.float32)\n",
        "\n",
        "# # Extract categorical features\n",
        "# train_categorical = torch.tensor(train_inputs_np[:, 0], dtype=torch.long).unsqueeze(1)  # Column 0\n",
        "# train_hs = torch.tensor(train_inputs_np[:, 4], dtype=torch.long).unsqueeze(1)  # Column 4\n",
        "# test_categorical = torch.tensor(test_inputs_np[:, 0], dtype=torch.long).unsqueeze(1)\n",
        "# test_hs = torch.tensor(test_inputs_np[:, 4], dtype=torch.long).unsqueeze(1)\n",
        "\n",
        "# # Combine PCA-transformed continuous features with categorical features\n",
        "# train_inputs_pca = torch.cat((train_categorical, X_train_continuous_pca_tensor, train_hs), dim=1)\n",
        "# test_inputs_pca = torch.cat((test_categorical, X_test_continuous_pca_tensor, test_hs), dim=1)\n",
        "\n",
        "# # Convert labels to PyTorch tensors\n",
        "# train_labels = torch.tensor(train_labels, dtype=torch.int)\n",
        "# test_labels = torch.tensor(test_labels, dtype=torch.int)\n",
        "\n",
        "# # Create TensorDatasets and DataLoaders\n",
        "# train_dataset_pca = TensorDataset(train_inputs_pca, train_labels)\n",
        "# test_dataset_pca = TensorDataset(test_inputs_pca, test_labels)\n",
        "# train_loader_pca = DataLoader(train_dataset_pca, batch_size=64, shuffle=True)\n",
        "# test_loader_pca = DataLoader(test_dataset_pca, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ZvnC5ENWH1DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class NeuralNetwork(nn.Module):\n",
        "#     def __init__(self, i, h_size, h_next_size, h_next_next_size=19, n_classes=2,\n",
        "#                  how_many_layers=4, embedding_dim=12, hs_embedding_dim=50):\n",
        "#         super(NeuralNetwork, self).__init__()\n",
        "\n",
        "#         # i is now train_inputs_pca; features = 2 categorical + PCA components\n",
        "#         n_continuous_pca = i.shape[1] - 2  # Subtract 2 for categorical columns (0 and last)\n",
        "\n",
        "#         # Define embedding layers\n",
        "#         self.major_embedding = nn.Embedding(num_embeddings=len(set(inputs[:, 0])), embedding_dim=embedding_dim)\n",
        "#         self.hs_embedding = nn.Embedding(num_embeddings=len(set(inputs[:, 4])), embedding_dim=hs_embedding_dim)\n",
        "\n",
        "#         # Input to fc1: embedding_dim (major) + hs_embedding_dim (hs) + n_continuous_pca\n",
        "#         self.fc1 = nn.Linear(n_continuous_pca + embedding_dim + hs_embedding_dim, h_size)\n",
        "#         self.layers = how_many_layers\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             self.fc2 = nn.Linear(h_size, n_classes)\n",
        "#         elif self.layers == 3:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, n_classes)\n",
        "#         elif self.layers == 4:\n",
        "#             self.fc3 = nn.Linear(h_size, h_next_size)\n",
        "#             self.fc4 = nn.Linear(h_next_size, h_next_next_size)\n",
        "#             self.fc5 = nn.Linear(h_next_next_size, n_classes)\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         # Extract categorical and continuous features\n",
        "#         categorical_input = X[:, 0].long()      # First column: major code\n",
        "#         hs_input = X[:, -1].long()              # Last column: high school code\n",
        "#         continuous_input = X[:, 1:-1].float()   # PCA components (middle columns)\n",
        "\n",
        "#         # Apply embeddings\n",
        "#         embedded = self.major_embedding(categorical_input)\n",
        "#         hs_embedded = self.hs_embedding(hs_input)\n",
        "\n",
        "#         # Concatenate\n",
        "#         X = torch.cat((embedded, hs_embedded, continuous_input), dim=1)\n",
        "\n",
        "#         if self.layers == 2:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = self.fc2(X)\n",
        "#         elif self.layers == 3:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = F.relu(self.fc3(X))\n",
        "#             X = self.fc4(X)\n",
        "#         elif self.layers == 4:\n",
        "#             X = F.relu(self.fc1(X))\n",
        "#             X = torch.tanh(self.fc3(X))\n",
        "#             X = F.sigmoid(self.fc4(X))\n",
        "#             X = self.fc5(X)\n",
        "\n",
        "#         return X\n",
        "\n",
        "# # Initialize the network with PCA-transformed inputs\n",
        "# net_pca = NeuralNetwork(train_inputs_pca, h_size=27, h_next_size=22, how_many_layers=4)\n",
        "# print(f\"Expected input features to fc1: {train_inputs_pca.shape[1] - 2 + 12 + 50}\")\n",
        "# print(f\"fc1 weight shape: {net_pca.fc1.weight.shape}\")"
      ],
      "metadata": {
        "id": "27MYtUK1LRos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_epochs = 600\n",
        "# learning_rate = 0.001\n",
        "# decay_rate = learning_rate / n_epochs\n",
        "# optimizer = optim.Adam(net_pca.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
        "# lambda_reg = 0.01\n",
        "\n",
        "# def loss_fn(model, outputs, targets):\n",
        "#     y_train = train_labels.numpy()\n",
        "#     class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "#     class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "#     cross_entropy = F.cross_entropy(outputs, targets, weight=class_weights_tensor)\n",
        "#     l2_regularization = sum(torch.norm(param, p=2) ** 2 for param in model.parameters())\n",
        "#     loss = cross_entropy + lambda_reg * l2_regularization\n",
        "#     return loss\n",
        "\n",
        "# def test_instance(model, loader=test_loader_pca):\n",
        "#     y_t = []\n",
        "#     y_s = []\n",
        "#     loss = 0\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in loader:\n",
        "#             outputs = model(inputs)\n",
        "#             loss += loss_fn(model, outputs, labels.long())\n",
        "#             y_t.extend(labels.numpy().astype('int'))\n",
        "#             y_s.extend(torch.argmax(outputs, dim=1).numpy())  # Use argmax instead of sigmoid for consistency\n",
        "#     acc = accuracy_score(y_t, y_s)\n",
        "#     return loss, acc\n",
        "\n",
        "# counter = 0\n",
        "# save_net = None\n",
        "\n",
        "# for epoch in range(n_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     total = 0\n",
        "#     correct = 0\n",
        "\n",
        "#     for i, (inputs, labels) in enumerate(train_loader_pca):\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = net_pca(inputs)\n",
        "#         loss = loss_fn(net_pca, outputs, labels.long())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item() * inputs.size(0)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     epoch_loss = running_loss / len(train_loader_pca.dataset)\n",
        "#     epoch_acc = correct / total\n",
        "\n",
        "#     if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
        "#         print(f'Epoch: {epoch + 1}/{n_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}')\n",
        "\n",
        "#     if epoch % 50 == 0:\n",
        "#         test_loss, test_acc = test_instance(net_pca)\n",
        "#         print(f'Epoch: {epoch + 1} | Test Accuracy = {test_acc:.4f} | Test Loss = {test_loss:.4f}')\n",
        "#         if counter < test_acc:\n",
        "#             save_net = net_pca\n",
        "#             counter = test_acc\n",
        "\n",
        "# # Final evaluation\n",
        "# y_true = []\n",
        "# y_scores = []\n",
        "# test_loss = 0\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in test_loader_pca:\n",
        "#         outputs = save_net(inputs)\n",
        "#         test_loss += loss_fn(save_net, outputs, labels.long())\n",
        "#         y_true.extend(labels.numpy().astype('int'))\n",
        "#         y_scores.extend(torch.argmax(outputs, dim=1).numpy())\n",
        "\n",
        "# accuracy = accuracy_score(y_true, y_scores)\n",
        "# precision = precision_score(y_true, y_scores)\n",
        "# recall = recall_score(y_true, y_scores)\n",
        "# f1_val = f1_score(y_true, y_scores)\n",
        "# auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "# print('Accuracy: {:.4f}'.format(accuracy))\n",
        "# print('Precision: {:.4f}'.format(precision))\n",
        "# print('Recall: {:.4f}'.format(recall))\n",
        "# print('F1 Score: {:.4f}'.format(f1_val))\n",
        "# print('AUROC Score: {:.4f}'.format(auc_roc))"
      ],
      "metadata": {
        "id": "pkofIN6yLTza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# # Print the matrix\n",
        "# print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# # Plot the Confusion Matrix\n",
        "# plt.figure(figsize=(6, 5))\n",
        "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "# plt.xlabel(\"Predicted Label\")\n",
        "# plt.ylabel(\"True Label\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.show()\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Compute Confusion Matrix\n",
        "# cm = confusion_matrix(y_true, y_scores)\n",
        "\n",
        "# # Extract TP, TN, FP, FN\n",
        "# TN = cm[0, 0]  # True Negative\n",
        "# FP = cm[0, 1]  # False Positive\n",
        "# FN = cm[1, 0]  # False Negative\n",
        "# TP = cm[1, 1]  # True Positive\n",
        "\n",
        "# print(f\"True Positives (TP): {TP}\")\n",
        "# print(f\"False Positives (FP): {FP}\")\n",
        "# print(f\"True Negatives (TN): {TN}\")\n",
        "# print(f\"False Negatives (FN): {FN}\")\n"
      ],
      "metadata": {
        "id": "i84qhcRwOTxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CsqDf8NOUmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzaDS-lzSu3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new inference"
      ],
      "metadata": {
        "id": "hkkhfTRuSyUI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKO37HQDckXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COAXjELOSz8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_2023=list(data.columns)\n",
        "l_2024=list(data1.columns)\n"
      ],
      "metadata": {
        "id": "j1378y3QcpIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in l_2024:\n",
        "  if col not in l_2023:\n",
        "    print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpmgwRK7U39c",
        "outputId": "c67b053b-1dc3-4584-92ba-ffa3e5e90ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High School Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qxmkjCMc_Ne",
        "outputId": "7ed10414-3f38-4be8-d42a-2aec691b7804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Application Major', 'Scholarship_Awarded', 'Application CGPA',\n",
              "       'FAFSA Filed', 'Financial Aid Appeal',\n",
              "       'Accepted Student Day Event Attended', 'Campus Visits - Person',\n",
              "       'Campus Visits - App', 'Logins Before Admit', 'Acceptance Call Success',\n",
              "       'Application Consider Test Scores', 'Application ACRK',\n",
              "       'Waitlist Confirmed Date', 'Emails Sent', 'Emails Opened',\n",
              "       'Was Inquiry', 'Athlete', 'admitted', 'Address 1 Region_Midwest',\n",
              "       'Address 1 Region_Northeast', 'Address 1 Region_South',\n",
              "       'Address 1 Region_Southwest', 'Address 1 Region_Territory',\n",
              "       'Address 1 Region_West', 'Application Housing_Commuter',\n",
              "       'Application Housing_Residential',\n",
              "       'Application Enroll Status_Full Time',\n",
              "       'Application Enroll Status_Part Time', 'Person Sex_F', 'Person Sex_M',\n",
              "       'High School Region_Midwest', 'High School Region_Northeast',\n",
              "       'High School Region_South', 'High School Region_Southwest',\n",
              "       'High School Region_Territory', 'High School Region_West',\n",
              "       'Application Span', 'Admission Span', 'Application College_00',\n",
              "       'Application College_CAS', 'Application College_COB',\n",
              "       'Application College_HCLC', 'Application College_ID',\n",
              "       'Application College_SHS', 'Application College_TCOE',\n",
              "       'Address 1 Region_Military', 'Person Sex_Unknown',\n",
              "       'High School Region_Military'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_inf=pd.read_csv(\"/content/final_pre_processed_2023 (2).csv\")\n",
        "inputs=data_inf.drop(['admitted'],axis=1).to_numpy()\n",
        "print(inputs.shape)\n",
        "labels=data_inf['admitted'].to_numpy()\n",
        "inputs=torch.tensor(inputs,dtype=torch.float32)\n",
        "labels=torch.tensor(labels,dtype=torch.float32)\n",
        "test_dataset = TensorDataset(inputs, labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "y_true = []\n",
        "y_scores = []\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = save_net(inputs)\n",
        "        test_loss += loss_fn(net, outputs, labels.long())\n",
        "        y_true.extend(labels.numpy().astype('int'))\n",
        "        y_scores.extend(torch.sigmoid(outputs).max(axis=1).indices.numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_scores)\n",
        "precision = precision_score(y_true, y_scores)\n",
        "recall = recall_score(y_true, y_scores)\n",
        "f1_val = f1_score(y_true, y_scores)\n",
        "auc_roc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_val))\n",
        "print('AUROC Score: {:.4f}'.format(auc_roc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "KR0pkdrqdtH_",
        "outputId": "d1458f4c-d3ba-4415-887f-8c29b1cfd5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9845, 47)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x107 and 108x27)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-8e48c7ca6b65>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d7aa20b6f3c6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x107 and 108x27)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "8iKyWQSdf8GP",
        "outputId": "4436bec3-8cdf-485e-bda0-c870a8b909d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'net' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d3e61c39d23b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_2qlTaGvrUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}